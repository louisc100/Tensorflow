{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2f7879",
   "metadata": {},
   "source": [
    "# Tensorflow Core Learning Algorithms 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552036fd",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Now that we've covered linear regression, it is time to talk about classification. Where regression was used to predict a numeric value, classification is used to seperate data points into classes of different labels. In this example we will use a TensorFlow estimator to classify flowers.\n",
    "\n",
    "Since we've touched on how estimators work earlier I'll go a bit quicker through this example.\n",
    "\n",
    "This section is based on the following guide from the TensorFlow website.\n",
    "https://www.tensorflow.org.tutorials/estimator/premade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d3463",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44b32c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71b5f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686605c",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "This specific dataset seperates floweres into 3 different classes of species.\n",
    "\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "The information about each flower is the following.\n",
    "\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3eb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Let's define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a4bb22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f1f9b",
   "metadata": {},
   "source": [
    "Let's take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dcb78ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ada48",
   "metadata": {},
   "source": [
    "Now, we can pop the species column off that use as our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aebc349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4e1660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ddaa3804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94515b",
   "metadata": {},
   "source": [
    "### Input Function\n",
    "Remember that nasty input function we created earlier. Well we need to make another one here! Fortunately for us this one is a little easier to digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1ac5ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64f5cb",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21f19281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/ipykernel_1328/3703507642.py:4: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10840d",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "And now we are ready to choose a model. For classification tasks, there are variety of different estimators/models that we can pick from.\n",
    "\n",
    "Some options are listed below.\n",
    "\n",
    "- `DNNClassifier` (Deep Neural Network)\n",
    "- `LinearClassifier`\n",
    "\n",
    "We can choose either model but DNN seems to be the best choice. This is because we may not be able to find a linear correspondence in our data.\n",
    "\n",
    "So let's build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cd88ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmpgeuka5q2\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmpgeuka5q2', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8a2e0",
   "metadata": {},
   "source": [
    "What we've just done is created a deep neural network that has two hidden layers. These layers have 30 and 10 neurons respectively. This is the number of neurons of the TensorFlow official tutorial uses so we'll stick with it. However, it is worth mentioning that the number of hidden neurons is an arbitrary number and many experiments and tests are usually done to determine the best choice for these values. Try playing around with the number of hidden neurons and see if your results change.\n",
    "\n",
    "`tf.estimator` stores a lot of pre-made models from TensorFlow.\n",
    "\n",
    "More explanation for neural network stuff later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff88d50",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now, it's time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8f71dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmpgeuka5q2/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 10000...\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmpgeuka5q2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 10000...\n",
      "INFO:tensorflow:loss = 0.26698333, step = 10000\n",
      "INFO:tensorflow:global_step/sec: 1363.58\n",
      "INFO:tensorflow:loss = 0.25577775, step = 10100 (0.074 sec)\n",
      "INFO:tensorflow:global_step/sec: 2051.5\n",
      "INFO:tensorflow:loss = 0.2571512, step = 10200 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2063.29\n",
      "INFO:tensorflow:loss = 0.25912893, step = 10300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2097.84\n",
      "INFO:tensorflow:loss = 0.24833803, step = 10400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2043.4\n",
      "INFO:tensorflow:loss = 0.26374197, step = 10500 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2036.16\n",
      "INFO:tensorflow:loss = 0.25212276, step = 10600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2108.59\n",
      "INFO:tensorflow:loss = 0.24347848, step = 10700 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2086.43\n",
      "INFO:tensorflow:loss = 0.2504053, step = 10800 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2078.66\n",
      "INFO:tensorflow:loss = 0.2505609, step = 10900 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2043.27\n",
      "INFO:tensorflow:loss = 0.24607939, step = 11000 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2041.06\n",
      "INFO:tensorflow:loss = 0.23783968, step = 11100 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2069.89\n",
      "INFO:tensorflow:loss = 0.24143013, step = 11200 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2081.11\n",
      "INFO:tensorflow:loss = 0.24978448, step = 11300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2092.76\n",
      "INFO:tensorflow:loss = 0.24005392, step = 11400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2092.32\n",
      "INFO:tensorflow:loss = 0.23409429, step = 11500 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2079.86\n",
      "INFO:tensorflow:loss = 0.22891822, step = 11600 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2071.29\n",
      "INFO:tensorflow:loss = 0.23685664, step = 11700 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2083.12\n",
      "INFO:tensorflow:loss = 0.22463709, step = 11800 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2076.41\n",
      "INFO:tensorflow:loss = 0.23264651, step = 11900 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2049.43\n",
      "INFO:tensorflow:loss = 0.2262735, step = 12000 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1993.11\n",
      "INFO:tensorflow:loss = 0.23064914, step = 12100 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1992.42\n",
      "INFO:tensorflow:loss = 0.2168006, step = 12200 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2045.41\n",
      "INFO:tensorflow:loss = 0.22750059, step = 12300 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2072.15\n",
      "INFO:tensorflow:loss = 0.22452371, step = 12400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2086.64\n",
      "INFO:tensorflow:loss = 0.22125252, step = 12500 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2044.91\n",
      "INFO:tensorflow:loss = 0.2230305, step = 12600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2035.33\n",
      "INFO:tensorflow:loss = 0.21980932, step = 12700 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2024.25\n",
      "INFO:tensorflow:loss = 0.20696983, step = 12800 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2043.69\n",
      "INFO:tensorflow:loss = 0.21822709, step = 12900 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2007.63\n",
      "INFO:tensorflow:loss = 0.21900804, step = 13000 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2063\n",
      "INFO:tensorflow:loss = 0.22002321, step = 13100 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2074.74\n",
      "INFO:tensorflow:loss = 0.21434468, step = 13200 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2012.55\n",
      "INFO:tensorflow:loss = 0.21342939, step = 13300 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2004.77\n",
      "INFO:tensorflow:loss = 0.20770252, step = 13400 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2026.55\n",
      "INFO:tensorflow:loss = 0.2164759, step = 13500 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2061.97\n",
      "INFO:tensorflow:loss = 0.21037483, step = 13600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1321.58\n",
      "INFO:tensorflow:loss = 0.21640481, step = 13700 (0.076 sec)\n",
      "INFO:tensorflow:global_step/sec: 2087.81\n",
      "INFO:tensorflow:loss = 0.20626298, step = 13800 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2077.63\n",
      "INFO:tensorflow:loss = 0.20302752, step = 13900 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2083.06\n",
      "INFO:tensorflow:loss = 0.19621415, step = 14000 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2112.87\n",
      "INFO:tensorflow:loss = 0.19883066, step = 14100 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2077.11\n",
      "INFO:tensorflow:loss = 0.20314443, step = 14200 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2075.21\n",
      "INFO:tensorflow:loss = 0.20845757, step = 14300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2083.25\n",
      "INFO:tensorflow:loss = 0.19049104, step = 14400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2071.12\n",
      "INFO:tensorflow:loss = 0.19349462, step = 14500 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2060.33\n",
      "INFO:tensorflow:loss = 0.19738677, step = 14600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2039.93\n",
      "INFO:tensorflow:loss = 0.19053108, step = 14700 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2053.35\n",
      "INFO:tensorflow:loss = 0.19661899, step = 14800 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1700.31\n",
      "INFO:tensorflow:loss = 0.19836439, step = 14900 (0.059 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 15000...\n",
      "INFO:tensorflow:Saving checkpoints for 15000 into /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmpgeuka5q2/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 15000...\n",
      "INFO:tensorflow:Loss for final step: 0.1926456.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x2956668d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "                 steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bbbf41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
