{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2f7879",
   "metadata": {},
   "source": [
    "# Tensorflow Core Learning Algorithms 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ff5f31d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552036fd",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Now that we've covered linear regression, it is time to talk about classification. Where regression was used to predict a numeric value, classification is used to seperate data points into classes of different labels. In this example we will use a TensorFlow estimator to classify flowers.\n",
    "\n",
    "Since we've touched on how estimators work earlier I'll go a bit quicker through this example.\n",
    "\n",
    "This section is based on the following guide from the TensorFlow website.\n",
    "https://www.tensorflow.org.tutorials/estimator/premade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0d3463",
   "metadata": {},
   "source": [
    "### Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "71b5f0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b686605c",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "This specific dataset seperates floweres into 3 different classes of species.\n",
    "\n",
    "- Setosa\n",
    "- Versicolor\n",
    "- Virginica\n",
    "\n",
    "The information about each flower is the following.\n",
    "\n",
    "- sepal length\n",
    "- sepal width\n",
    "- petal length\n",
    "- petal width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "5f3eb885",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'Species']\n",
    "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
    "# Let's define some constants to help us later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a4bb22e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
    "# Here we use keras (a module inside of TensorFlow) to grab our datasets and read them into a pandas dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1f1f9b",
   "metadata": {},
   "source": [
    "Let's take a look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "7dcb78ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth  Species\n",
       "0          6.4         2.8          5.6         2.2        2\n",
       "1          5.0         2.3          3.3         1.0        1\n",
       "2          4.9         2.5          4.5         1.7        2\n",
       "3          4.9         3.1          1.5         0.1        0\n",
       "4          5.7         3.8          1.7         0.3        0"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ada48",
   "metadata": {},
   "source": [
    "Now, we can pop the species column off that use as our label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "aebc349d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLength</th>\n",
       "      <th>SepalWidth</th>\n",
       "      <th>PetalLength</th>\n",
       "      <th>PetalWidth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLength  SepalWidth  PetalLength  PetalWidth\n",
       "0          6.4         2.8          5.6         2.2\n",
       "1          5.0         2.3          3.3         1.0\n",
       "2          4.9         2.5          4.5         1.7\n",
       "3          4.9         3.1          1.5         0.1\n",
       "4          5.7         3.8          1.7         0.3"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = train.pop('Species')\n",
    "test_y = test.pop('Species')\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b4e1660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 4)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ddaa3804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    1\n",
       "2    2\n",
       "3    0\n",
       "4    0\n",
       "Name: Species, dtype: int64"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b94515b",
   "metadata": {},
   "source": [
    "### Input Function\n",
    "Remember that nasty input function we created earlier. Well we need to make another one here! Fortunately for us this one is a little easier to digest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1ac5ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa64f5cb",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "21f19281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NumericColumn(key='SepalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='SepalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalLength', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), NumericColumn(key='PetalWidth', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]\n"
     ]
    }
   ],
   "source": [
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for key in train.keys():\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "print(my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10840d",
   "metadata": {},
   "source": [
    "### Building the Model\n",
    "And now we are ready to choose a model. For classification tasks, there are variety of different estimators/models that we can pick from.\n",
    "\n",
    "Some options are listed below.\n",
    "\n",
    "- `DNNClassifier` (Deep Neural Network)\n",
    "- `LinearClassifier`\n",
    "\n",
    "We can choose either model but DNN seems to be the best choice. This is because we may not be able to find a linear correspondence in our data.\n",
    "\n",
    "So let's build a model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "cd88ea16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build a DNN with 2 hidden layers with 30 and 10 hidden nodes each.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 30 and 10 nodes respectively.\n",
    "    hidden_units=[30,10],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e8a2e0",
   "metadata": {},
   "source": [
    "What we've just done is created a deep neural network that has two hidden layers. These layers have 30 and 10 neurons respectively. This is the number of neurons of the TensorFlow official tutorial uses so we'll stick with it. However, it is worth mentioning that the number of hidden neurons is an arbitrary number and many experiments and tests are usually done to determine the best choice for these values. Try playing around with the number of hidden neurons and see if your results change.\n",
    "\n",
    "`tf.estimator` stores a lot of pre-made models from TensorFlow.\n",
    "\n",
    "More explanation for neural network stuff later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff88d50",
   "metadata": {},
   "source": [
    "### Training\n",
    "Now, it's time to train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "8f71dee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
      "INFO:tensorflow:loss = 1.6863942, step = 0\n",
      "INFO:tensorflow:global_step/sec: 1213.3\n",
      "INFO:tensorflow:loss = 1.14976, step = 100 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 2117.3\n",
      "INFO:tensorflow:loss = 1.0080228, step = 200 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2085.76\n",
      "INFO:tensorflow:loss = 0.9451312, step = 300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2092.66\n",
      "INFO:tensorflow:loss = 0.9066018, step = 400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2056.09\n",
      "INFO:tensorflow:loss = 0.8698787, step = 500 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2108.5\n",
      "INFO:tensorflow:loss = 0.84096324, step = 600 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2116.45\n",
      "INFO:tensorflow:loss = 0.8107569, step = 700 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2005.01\n",
      "INFO:tensorflow:loss = 0.80016625, step = 800 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 2017.71\n",
      "INFO:tensorflow:loss = 0.7713574, step = 900 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1795.59\n",
      "INFO:tensorflow:loss = 0.7419245, step = 1000 (0.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1756.98\n",
      "INFO:tensorflow:loss = 0.7246263, step = 1100 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1694.31\n",
      "INFO:tensorflow:loss = 0.70816535, step = 1200 (0.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 1716.5\n",
      "INFO:tensorflow:loss = 0.6866087, step = 1300 (0.058 sec)\n",
      "INFO:tensorflow:global_step/sec: 2060.37\n",
      "INFO:tensorflow:loss = 0.6717874, step = 1400 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2028.6\n",
      "INFO:tensorflow:loss = 0.66744626, step = 1500 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1804.54\n",
      "INFO:tensorflow:loss = 0.6435312, step = 1600 (0.056 sec)\n",
      "INFO:tensorflow:global_step/sec: 1643.38\n",
      "INFO:tensorflow:loss = 0.63568187, step = 1700 (0.062 sec)\n",
      "INFO:tensorflow:global_step/sec: 1217.61\n",
      "INFO:tensorflow:loss = 0.61555815, step = 1800 (0.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 794.538\n",
      "INFO:tensorflow:loss = 0.60457766, step = 1900 (0.125 sec)\n",
      "INFO:tensorflow:global_step/sec: 2122.87\n",
      "INFO:tensorflow:loss = 0.5958822, step = 2000 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 1942.62\n",
      "INFO:tensorflow:loss = 0.583147, step = 2100 (0.051 sec)\n",
      "INFO:tensorflow:global_step/sec: 2043.49\n",
      "INFO:tensorflow:loss = 0.5878496, step = 2200 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2097.18\n",
      "INFO:tensorflow:loss = 0.5697129, step = 2300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2089.51\n",
      "INFO:tensorflow:loss = 0.5570713, step = 2400 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2097.8\n",
      "INFO:tensorflow:loss = 0.5469372, step = 2500 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2047.37\n",
      "INFO:tensorflow:loss = 0.5375318, step = 2600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2039.65\n",
      "INFO:tensorflow:loss = 0.52886635, step = 2700 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2027.12\n",
      "INFO:tensorflow:loss = 0.5234238, step = 2800 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 1866.78\n",
      "INFO:tensorflow:loss = 0.5088315, step = 2900 (0.055 sec)\n",
      "INFO:tensorflow:global_step/sec: 1856.6\n",
      "INFO:tensorflow:loss = 0.49747407, step = 3000 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1993.03\n",
      "INFO:tensorflow:loss = 0.48346102, step = 3100 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1983.33\n",
      "INFO:tensorflow:loss = 0.49640834, step = 3200 (0.050 sec)\n",
      "INFO:tensorflow:global_step/sec: 1932.26\n",
      "INFO:tensorflow:loss = 0.47309625, step = 3300 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1896.71\n",
      "INFO:tensorflow:loss = 0.45840898, step = 3400 (0.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 1744.77\n",
      "INFO:tensorflow:loss = 0.45537832, step = 3500 (0.057 sec)\n",
      "INFO:tensorflow:global_step/sec: 1916.6\n",
      "INFO:tensorflow:loss = 0.46076596, step = 3600 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 1869.4\n",
      "INFO:tensorflow:loss = 0.4569681, step = 3700 (0.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 1859.46\n",
      "INFO:tensorflow:loss = 0.4357757, step = 3800 (0.054 sec)\n",
      "INFO:tensorflow:global_step/sec: 2056.34\n",
      "INFO:tensorflow:loss = 0.440505, step = 3900 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2137.62\n",
      "INFO:tensorflow:loss = 0.42944416, step = 4000 (0.047 sec)\n",
      "INFO:tensorflow:global_step/sec: 2057.15\n",
      "INFO:tensorflow:loss = 0.42483902, step = 4100 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2094.9\n",
      "INFO:tensorflow:loss = 0.42559817, step = 4200 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2083.68\n",
      "INFO:tensorflow:loss = 0.413181, step = 4300 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 1923.97\n",
      "INFO:tensorflow:loss = 0.41993725, step = 4400 (0.052 sec)\n",
      "INFO:tensorflow:global_step/sec: 2074.25\n",
      "INFO:tensorflow:loss = 0.40817887, step = 4500 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2046.71\n",
      "INFO:tensorflow:loss = 0.398042, step = 4600 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2074\n",
      "INFO:tensorflow:loss = 0.39190024, step = 4700 (0.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 2054.74\n",
      "INFO:tensorflow:loss = 0.39800283, step = 4800 (0.049 sec)\n",
      "INFO:tensorflow:global_step/sec: 2066.24\n",
      "INFO:tensorflow:loss = 0.39245734, step = 4900 (0.048 sec)\n",
      "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 5000...\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt.\n",
      "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 5000...\n",
      "INFO:tensorflow:Loss for final step: 0.39234397.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifierV2 at 0x31100a810>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=lambda: input_fn(train, train_y, training=True),\n",
    "                 steps=5000)\n",
    "# We include a lambda to avoid creating an inner function previously"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744ae339",
   "metadata": {},
   "source": [
    "The lower the \"loss\" the better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854596d",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "Let's see how it performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "d8bbbf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2025-08-26T09:47:13\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Inference Time : 0.10611s\n",
      "INFO:tensorflow:Finished evaluation at 2025-08-26-09:47:13\n",
      "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.93333334, average_loss = 0.44920492, global_step = 5000, loss = 0.44920492\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt-5000\n"
     ]
    }
   ],
   "source": [
    "eval_result = classifier.evaluate(input_fn=lambda: input_fn(test, test_y, training=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "8a0eb708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set accuracy: 0.933\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTest set accuracy: {accuracy:0.3f}\\n\".format(**eval_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b304b35",
   "metadata": {},
   "source": [
    "### Predictions\n",
    "Let's see how this model predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "efd0fe90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please type numeric value as prompted.\n",
      "\"SepalLength\": \"2.1\"\n",
      "\"SepalWidth\": \"3.2\"\n",
      "\"PetalLength\": \"4.5\"\n",
      "\"PetalWidth\": \"7.2\"\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "{'logits': array([0.3716182 , 0.09661669, 4.073316  ], dtype=float32), 'probabilities': array([0.0236543 , 0.01796712, 0.95837855], dtype=float32), 'class_ids': array([2]), 'classes': array([b'2'], dtype=object), 'all_class_ids': array([0, 1, 2], dtype=int32), 'all_classes': array([b'0', b'1', b'2'], dtype=object)}\n",
      "Predictions is \"Virginica\" (95.8%)\n"
     ]
    }
   ],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric value as prompted.\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        print('\"{}\": \"{}\"'.format(feature, val))\n",
    "        if not val.isdigit(): valid = False\n",
    "\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    print(pred_dict)\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Predictions is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "4159459c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some example input and and expected classes you can try above\n",
    "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
    "predict_x = {\n",
    "    'SepalLength': [5.1, 5.9, 6.9],\n",
    "    'SepalWidth': [3.3, 3.0, 3.1],\n",
    "    'PetalLength': [1.7, 4.2, 5.4],\n",
    "    'PetalWidth': [0.5, 1.5, 2.1],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "7233ed68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/3q/7940jm5955s9rqks86c04zcc0000gn/T/tmp86vak7qe/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "Predictions is \"Setosa\" (84.5%), expected is Setosa\n",
      "Predictions is \"Versicolor\" (52.9%), expected is Versicolor\n",
      "Predictions is \"Virginica\" (60.6%), expected is Virginica\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict_x))\n",
    "i = 0\n",
    "for pred_dict in predictions:\n",
    "    i += 1\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Predictions is \"{}\" ({:.1f}%), expected is {}'.format(\n",
    "        SPECIES[class_id], 100 * probability, expected[i-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
